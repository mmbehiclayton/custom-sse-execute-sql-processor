<extensionManifest><groupId>com.sse.processors</groupId><artifactId>nifi-sse-execute-sql-nar</artifactId><version>2.1.0</version><parentNar><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-nar</artifactId><version>2.1.0</version></parentNar><systemApiVersion>2.1.0</systemApiVersion><buildInfo><tag>HEAD</tag></buildInfo><extensions><extension><name>com.sse.processors.SseExecuteSQL</name><type>PROCESSOR</type><description>SSE ExecuteSQL - Executes provided SQL select query with optional environment validation. When validation is disabled, functions exactly like standard ExecuteSQL. When validation is enabled, validates that controller services match the expected environment configuration by querying the SSE Engine database using operation_id from FlowFile attributes. **IMPORTANT: When validation is enabled, SQL execution is gated by validation results - the SQL query will ONLY execute if validation passes.** Query result will be converted to Avro format. Streaming is used so arbitrarily large result sets are supported. This processor can be scheduled to run on a timer, or cron expression, using the standard scheduling methods, or it can be triggered by an incoming FlowFile. If it is triggered by an incoming FlowFile, then attributes of that FlowFile will be available when evaluating the select query, and the query may use the ? to escape parameters. In this case, the parameters to use must exist as FlowFile attributes with the naming convention sql.args.N.type and sql.args.N.value, where N is a positive integer. The sql.args.N.type is expected to be a number indicating the JDBC Type. The content of the FlowFile is expected to be in UTF-8 format. FlowFile attribute 'executesql.row.count' indicates how many rows were selected.</description><tags><tag>sql</tag><tag>select</tag><tag>jdbc</tag><tag>query</tag><tag>database</tag><tag>sse</tag><tag>validation</tag></tags><properties><property><name>enable-validation</name><displayName>Enable Validation</displayName><description>Enable or disable environment validation. Set to false only for testing or emergency bypass.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Connection Pooling Service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain connection to database</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.1.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sql-pre-query</name><displayName>SQL Pre-Query</displayName><description>A semicolon-delimited list of queries executed before the main SQL query is executed. For example, set session properties before main query. It's possible to include semicolons in the statements themselves by escaping them with a backslash ('\;'). Results/outputs from these queries will be suppressed if there are no errors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SQL select query</name><displayName>SQL select query</displayName><description>The SQL select query to execute. The query can be empty, a constant value, or built from attributes using Expression Language. If this property is specified, it will be used regardless of the content of incoming flowfiles. If this property is empty, the content of the incoming flow file is expected to contain a valid SQL select query, to be issued by the processor to the database. Note that Expression Language is not evaluated for flow file contents.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sql-post-query</name><displayName>SQL Post-Query</displayName><description>A semicolon-delimited list of queries executed after the main SQL query is executed. Example like setting session properties after main query. It's possible to include semicolons in the statements themselves by escaping them with a backslash ('\;'). Results/outputs from these queries will be suppressed if there are no errors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Wait Time</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-normalize</name><displayName>Normalize Table/Column Names</displayName><description>Whether to change non-Avro-compatible characters in column names to Avro-compatible characters. For example, colons and periods will be changed to underscores in order to build a valid Avro record.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-user-logical-types</name><displayName>Use Avro Logical Types</displayName><description>Whether to use Avro Logical Types for DECIMAL/NUMBER, DATE, TIME and TIMESTAMP columns. If disabled, written as string. If enabled, Logical types are used and written as its underlying type, specifically, DECIMAL/NUMBER as logical 'decimal': written as bytes with additional precision and scale meta data, DATE as logical 'date-millis': written as int denoting days since Unix epoch (1970-01-01), TIME as logical 'time-millis': written as int denoting milliseconds since Unix epoch, and TIMESTAMP as logical 'timestamp-millis': written as long denoting milliseconds since Unix epoch. If a reader of written Avro records also knows these logical types, then these values can be deserialized with more context depending on reader implementation.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>compression-format</name><displayName>Compression Format</displayName><description>Compression type to use when writing Avro files. Default is None.</description><defaultValue>NONE</defaultValue><allowableValues><allowableValue><displayName>BZIP2</displayName><value>BZIP2</value><description></description></allowableValue><allowableValue><displayName>DEFLATE</displayName><value>DEFLATE</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue><allowableValue><displayName>SNAPPY</displayName><value>SNAPPY</value><description></description></allowableValue><allowableValue><displayName>LZO</displayName><value>LZO</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-max-rows</name><displayName>Max Rows Per Flow File</displayName><description>The maximum number of result rows that will be included in a single FlowFile. This will allow you to break up very large result sets into multiple FlowFiles. If the value specified is zero, then all rows are returned in a single FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-output-batch-size</name><displayName>Output Batch Size</displayName><description>The number of output FlowFiles to queue before committing the process session. When set to zero, the session will be committed when all result set rows have been processed and the output FlowFiles are ready for transfer to the downstream relationship. For large result sets, this can cause a large burst of FlowFiles to be transferred at the end of processor execution. If this property is set, then when the specified number of FlowFiles are ready for transfer, then the session will be committed, thus releasing the FlowFiles to the downstream relationship. NOTE: The fragment.count attribute will not be set on FlowFiles when this property is set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-fetch-size</name><displayName>Fetch Size</displayName><description>The number of result rows to be fetched from the result set at a time. This is a hint to the database driver and may not be honored and/or exact. If the value specified is zero, then the hint is ignored.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-auto-commit</name><displayName>Set Auto Commit</displayName><description>Enables or disables the auto commit functionality of the DB connection. Default value is 'true'. The default value can be used with most of the JDBC drivers and this functionality doesn't have any impact in most of the cases since this processor is used to read data. However, for some JDBC drivers such as PostgreSQL driver, it is required to disable the auto committing functionality to limit the number of result rows fetching at a time. When auto commit is enabled, postgreSQL driver loads whole result set to memory at once. This could lead for a large amount of memory usage when executing queries which fetch large data sets. More Details of this behaviour in PostgreSQL driver can be found in https://jdbc.postgresql.org//documentation/head/query.html. </description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>operation-id</name><displayName>Operation ID</displayName><description>The operation ID from FlowFile attributes. Used to look up environment configuration from sse_engine.data_migration_records table. **REQUIRED when Enable Validation is true.** Ignored when Enable Validation is false.</description><defaultValue>${operation_id}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>enable-validation</propertyName><propertyDisplayName>Enable Validation</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>engine-dbcp-service</name><displayName>SSE Engine DBCP Service</displayName><description>The DBCP Controller Service for connecting to the SSE Engine database (sse_engine schema) to query environment configurations. Typically DBCP_NCBA_SSE_ENGINE. **REQUIRED when Enable Validation is true.** Ignored when Enable Validation is false.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.1.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>enable-validation</propertyName><propertyDisplayName>Enable Validation</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>source-dbcp-service</name><displayName>Source DBCP Service</displayName><description>The DBCP Controller Service to validate against the environment's source configuration. Typically DBCP_NCBA_SSE_SOURCE. **REQUIRED when Enable Validation is true.** Ignored when Enable Validation is false.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.1.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>enable-validation</propertyName><propertyDisplayName>Enable Validation</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>target-dbcp-service</name><displayName>Target DBCP Service</displayName><description>The DBCP Controller Service to validate against the environment's target configuration. Typically DBCP_NCBA_SSE_TARGET. **REQUIRED when Enable Validation is true.** Ignored when Enable Validation is false.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.1.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>enable-validation</propertyName><propertyDisplayName>Enable Validation</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>validation-mode</name><displayName>Validation Mode</displayName><description>Determines validation behavior: STRICT (route to failure on mismatch) or WARNING (log warning and continue). **REQUIRED when Enable Validation is true.** Ignored when Enable Validation is false.</description><defaultValue>STRICT</defaultValue><allowableValues><allowableValue><displayName>STRICT</displayName><value>STRICT</value><description></description></allowableValue><allowableValue><displayName>WARNING</displayName><value>WARNING</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>enable-validation</propertyName><propertyDisplayName>Enable Validation</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property></properties><dynamicProperties><dynamicProperty><name>sql.args.N.type</name><value>SQL type argument to be supplied</value><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter. The following types are accepted: [LONGNVARCHAR: -16], [BIT: -7], [BOOLEAN: 16], [TINYINT: -6], [BIGINT: -5], [LONGVARBINARY: -4], [VARBINARY: -3], [BINARY: -2], [LONGVARCHAR: -1], [CHAR: 1], [NUMERIC: 2], [DECIMAL: 3], [INTEGER: 4], [SMALLINT: 5] [FLOAT: 6], [REAL: 7], [DOUBLE: 8], [VARCHAR: 12], [DATE: 91], [TIME: 92], [TIMESTAMP: 93], [VARCHAR: 12], [CLOB: 2005], [NCLOB: 2011]</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>sql.args.N.value</name><value>Argument to be supplied</value><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>sql.args.N.format</name><value>SQL format argument to be supplied</value><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><supportsSensitiveDynamicProperties>true</supportsSensitiveDynamicProperties><relationships><relationship><name>validation_failed</name><description>FlowFiles that fail environment validation are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>sql.args.N.type</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter. The following types are accepted: [LONGNVARCHAR: -16], [BIT: -7], [BOOLEAN: 16], [TINYINT: -6], [BIGINT: -5], [LONGVARBINARY: -4], [VARBINARY: -3], [BINARY: -2], [LONGVARCHAR: -1], [CHAR: 1], [NUMERIC: 2], [DECIMAL: 3], [INTEGER: 4], [SMALLINT: 5] [FLOAT: 6], [REAL: 7], [DOUBLE: 8], [VARCHAR: 12], [DATE: 91], [TIME: 92], [TIMESTAMP: 93], [VARCHAR: 12], [CLOB: 2005], [NCLOB: 2011]</description></readsAttribute><readsAttribute><name>sql.args.N.value</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description></readsAttribute><readsAttribute><name>sql.args.N.format</name><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description></readsAttribute><readsAttribute><name>operation_id</name><description>Operation ID used for environment validation when validation is enabled.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>executesql.row.count</name><description>Contains the number of rows returned by the query. If 'Max Rows Per Flow File' is set, then this number will reflect the number of rows in the Flow File instead of the entire result set.</description></writesAttribute><writesAttribute><name>executesql.query.duration</name><description>Combined duration of the query execution time and fetch time in milliseconds. If 'Max Rows Per Flow File' is set, then this number will reflect only the fetch time for the rows in the Flow File instead of the entire result set.</description></writesAttribute><writesAttribute><name>executesql.query.executiontime</name><description>Duration of the query execution time in milliseconds. This number will reflect the query execution time regardless of the 'Max Rows Per Flow File' setting.</description></writesAttribute><writesAttribute><name>executesql.query.fetchtime</name><description>Duration of the result set fetch time in milliseconds. If 'Max Rows Per Flow File' is set, then this number will reflect only the fetch time for the rows in the Flow File instead of the entire result set.</description></writesAttribute><writesAttribute><name>executesql.resultset.index</name><description>Assuming multiple result sets are returned, the zero based index of this result set.</description></writesAttribute><writesAttribute><name>executesql.error.message</name><description>If processing an incoming flow file causes an Exception, the Flow File is routed to failure and this attribute is set to the exception message.</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>If 'Max Rows Per Flow File' is set then all FlowFiles from the same query result set will have the same value for the fragment.identifier attribute. This can then be used to correlate the results.</description></writesAttribute><writesAttribute><name>fragment.count</name><description>If 'Max Rows Per Flow File' is set then this is the total number of  FlowFiles produced by a single ResultSet. This can be used in conjunction with the fragment.identifier attribute in order to know how many FlowFiles belonged to the same incoming ResultSet. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute><writesAttribute><name>fragment.index</name><description>If 'Max Rows Per Flow File' is set then the position of this FlowFile in the list of outgoing FlowFiles that were all derived from the same result set FlowFile. This can be used in conjunction with the fragment.identifier attribute to know which FlowFiles originated from the same query result set and in what order  FlowFiles were produced</description></writesAttribute><writesAttribute><name>input.flowfile.uuid</name><description>If the processor has an incoming connection, outgoing FlowFiles will have this attribute set to the value of the input FlowFile's UUID. If there is no incoming connection, the attribute will not be added.</description></writesAttribute><writesAttribute><name>validation.passed</name><description>true if validation passed</description></writesAttribute><writesAttribute><name>validation.environment.id</name><description>Environment ID used for validation</description></writesAttribute><writesAttribute><name>validation.environment.name</name><description>Environment name</description></writesAttribute><writesAttribute><name>validation.timestamp</name><description>Validation timestamp</description></writesAttribute><writesAttribute><name>validation.error</name><description>Validation error message if failed</description></writesAttribute></writesAttributes><inputRequirement>INPUT_ALLOWED</inputRequirement></extension></extensions></extensionManifest>